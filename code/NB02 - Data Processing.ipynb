{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages and custom python functions for cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime\n",
    "\n",
    "import data_cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in Raw Data \n",
    "The data is found in the charts_song_data.json ad the unemployment.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_df = pd.read_json(\"../data/raw/charts_song_data.json\")\n",
    "unemployment_df = pd.read_json(\"../data/raw/unemployment.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean and Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns in the Charts data frame for clarity, reformat the song and artist names for consistency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_df = charts_df.T.reset_index()\n",
    "charts_df.columns = [\"unique_id\", \"song\", \"artist\", \"track_id\", \"artist_id\", \"trending_year\", \"release_date\", \"genres\"]\n",
    "charts_df['song'] = charts_df['song'].str.lower().str.strip('\"').str.strip(\"'\").str.strip()\n",
    "charts_df['artist'] = charts_df['artist'].str.lower().str.strip('\"').str.strip(\"'\").str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split artists that collaborated on the same song into separate entities using custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_df[\"artist\"] = charts_df[\"artist\"].apply(data_cleaning.split_artists)\n",
    "charts_df = charts_df.explode(\"artist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the year each song was released from the full date for easier analysis with unemployment statistics using custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_df['release_year'] = charts_df['release_date'].apply(data_cleaning.clean_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created broad genre categories (Rap/Hip-Hop, Pop, R&B, Rock, Jazz, Latin, Indie, Country) to draw connections between simmilar sub-genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_df = charts_df.explode('genres').reset_index(drop=True)\n",
    "charts_df['genre_category'] = charts_df['genres'].apply(data_cleaning.categorize_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and rename the unemployment statistical table, filter out for just the years I need (1970-2023; the range of release dates for the songs on the charts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_df.columns = [\"year\", \"unemployment_rate\"]\n",
    "unemployment_df['year'] = unemployment_df['year'].apply(data_cleaning.clean_year)\n",
    "unemployment_df['year'] = pd.to_numeric(unemployment_df['year'], errors='coerce')\n",
    "unemployment_df = unemployment_df[unemployment_df['year'] >= 1970]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create SQL Data Base\n",
    "\n",
    "Create a SQLite data base called topcharts with the following structure:\n",
    "1. charts: track_id, trending year\n",
    "2. songs: track_id, artist_id, track_title\n",
    "3. artists: artist_id, artist_name\n",
    "4. artist_genres: artist_id, genre\n",
    "5. unemployment: year, unemployment_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/topcharts.db', echo=False, isolation_level=\"AUTOCOMMIT\")\n",
    "with engine.connect() as conn:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some primary keys had to be composite because there were non-unqiue columns. \n",
    "1. In the charts table, some songs were popular in more than one year. year was not unique because it applied to the 40 trending songs (per year). Therefore, the primary key, in order to be unique, had to be composite of trending year and track id\n",
    "2. Similarly, for the artists table, if 2 artists collaborated on the same song, there was a unique artist id for their collaboration. I wanted the artist names serparated from the collaboration so that I could identify indivdual artists popularity (including collaborations), but this meant that artist_id was not unique as it was repeated for each artist in the collaboration (and artist name was also not unique because it would also repeat for multiple ids if they had collaborations). Therefore I had to create another composite key. \n",
    "3. For the artist_genre table, the artists were not unique because they were repeated for each genre corresponding to their name, and the genres were not unique because they were repeated for each artist they applied to. Again, I used a composite key to retain all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_statement_charts = \"\"\"\n",
    "    CREATE TABLE charts (\n",
    "        track_id CHAR(25),\n",
    "        trending_year DATETIME,\n",
    "        PRIMARY KEY (track_id, trending_year)\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "create_statement_songs = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS songs (\n",
    "        track_id CHAR(25) PRIMARY KEY,\n",
    "        track_title VARCHAR(100),\n",
    "        artist_id CHAR(25),\n",
    "        FOREIGN KEY (artist_id) REFERENCES songs(artist_id)\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "create_statement_artists = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS artists (\n",
    "    artist_id CHAR(22),\n",
    "    artist_name VARCHAR(100),\n",
    "    PRIMARY KEY (artist_id, artist_name)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "create_statement_artist_genres = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS artist_genres (\n",
    "        artist_id CHAR(25),\n",
    "        genre VARCHAR(50),\n",
    "        PRIMARY KEY (artist_id, genre),\n",
    "        FOREIGN KEY (artist_id) REFERENCES artists(artist_id)\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "create_statement_genres = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS genres (\n",
    "        sub_genre CHAR(25) PRIMARY KEY,\n",
    "        genre VARCHAR(50),\n",
    "        FOREIGN KEY (sub_genre) REFERENCES artist_genres(genre)\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "create_statement_unemployment = \"\"\" \n",
    "    CREATE TABLE IF NOT EXISTS unemployment (\n",
    "        year DATETIME PRIMARY KEY,\n",
    "        unemployment FLOAT\n",
    "        );\n",
    "    \"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_statement_charts))\n",
    "    conn.execute(text(create_statement_songs))\n",
    "    conn.execute(text(create_statement_artists))\n",
    "    conn.execute(text(create_statement_artist_genres))\n",
    "    conn.execute(text(create_statement_unemployment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_sql_df = charts_df[['track_id', 'trending_year']].drop_duplicates(subset=['track_id', 'trending_year'])\n",
    "songs_sql_df = charts_df[['track_id', 'song', 'artist_id']].rename(columns={'song': 'track_title'}).drop_duplicates(subset='track_id', keep='last')\n",
    "artists_sql_df = charts_df[['artist_id', 'artist']].rename(columns={'artist': 'artist_name'}).drop_duplicates()\n",
    "artist_genres_df = charts_df[['artist_id', 'genres']].rename(columns={'genres': 'genre'}).drop_duplicates()\n",
    "charts_sql_df = charts_df[['track_id', 'trending_year']].drop_duplicates(subset=['track_id', 'trending_year'])\n",
    "genre_sql_df = charts_df[['genres', 'genre_category']].rename(columns={'genres': 'sub_genre', 'genre_category': 'genre'}).drop_duplicates()\n",
    "unemployment_sql_df = unemployment_df.rename(columns={'unemployment_rate': 'unemployment'}).drop_duplicates()\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    charts_sql_df.to_sql('charts', conn, if_exists='append', index=False)\n",
    "    songs_sql_df.to_sql('songs', conn, if_exists='append', index=False)\n",
    "    artists_sql_df.to_sql('artists', conn, if_exists='append', index=False)\n",
    "    artist_genres_df.to_sql('artist_genres', conn, if_exists='append', index=False)\n",
    "    genre_sql_df.to_sql('genres', conn, if_exists='append', index=False)\n",
    "    unemployment_sql_df.to_sql('unemployment', conn, if_exists='append', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
